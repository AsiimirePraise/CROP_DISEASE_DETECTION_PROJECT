{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12457032,"sourceType":"datasetVersion","datasetId":7857999}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.applications import EfficientNetB0  # Added for transfer learning\nimport os\nimport cv2\nimport numpy as np\nimport shutil\nfrom PIL import Image\nfrom collections import defaultdict\nimport hashlib\nfrom collections import Counter","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\nprint(\"GPU Available:\", tf.config.list_physical_devices('GPU'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**IMAGE PREPROCESSING**\n*1.1 Crop distribution*","metadata":{}},{"cell_type":"code","source":"# Dataset analysis\nDATASET_DIR = \"/kaggle/input/crop-disease-dataset/disease/train\"\nclass_counts = {}\nfor class_name in os.listdir(DATASET_DIR):\n    class_path = os.path.join(DATASET_DIR, class_name)\n    if os.path.isdir(class_path):\n        images = [f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n        class_counts[class_name] = len(images)\n\nprint(\"----------------------Class Distribution:--------------------------\\n\")\nfor class_name, count in class_counts.items():\n    print(f\"{class_name}: {count} images\")\n\n# Total images and classes calculation\ntotal_images = sum(class_counts.values())\nn_classes = len(class_counts)\nprint(f\"\\n----------------------------------Dataset Summary:-----------------------\")\nprint(f\"Total images: {total_images}\")\nprint(f\"Number of classes: {n_classes}\")\nprint(f\"Average images per class: {total_images/n_classes:.1f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Find min and max class sizes\nmin_images = min(class_counts.values())\nmax_images = max(class_counts.values())\nmin_class_name = min(class_counts, key=class_counts.get)\nmax_class_name = max(class_counts, key=class_counts.get)\nprint(f\"Smallest class \\n{min_class_name}=> {min_images} images\\n\")\nprint(f\"Largest class \\n{max_class_name}=> {max_images} images\\n\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"*Check for duplicates*","metadata":{}},{"cell_type":"code","source":"print(\"-------------------Counting images in each class----------------------------------\")\nimage_extensions=('.jpg', '.jpeg', '.png')      \nfor class_name in os.listdir(DATASET_DIR):\n    class_path = os.path.join(DATASET_DIR, class_name)\n    if os.path.isdir(class_path):\n        images = [f for f in os.listdir(class_path) \n        if f.lower().endswith(image_extensions)]\n        class_counts[class_name] = len(images)\nprint(class_counts)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Dataset balance analysis\nif class_counts: \n    counts = list(class_counts.values())\n    total_images = sum(counts)\n    n_classes = len(class_counts)\n    \n    analysis_results = {\n        'total_images': total_images,\n        'n_classes': n_classes,\n        'average_per_class': total_images / n_classes,\n        'min_images': min(counts),\n        'max_images': max(counts),\n        'std_dev': np.std(counts),\n        'median': np.median(counts)\n    }\n    \n    min_class = min(class_counts, key=class_counts.get)\n    max_class = max(class_counts, key=class_counts.get)\n    \n    analysis_results['min_class'] = min_class\n    analysis_results['max_class'] = max_class\n    \n    imbalance_ratio = analysis_results['max_images'] / analysis_results['min_images']\n    analysis_results['imbalance_ratio'] = imbalance_ratio\n    \n    if imbalance_ratio < 2:\n        balance_status = \"Well Balanced\"\n    elif imbalance_ratio < 5:\n        balance_status = \"Slightly Imbalanced\"\n    elif imbalance_ratio < 10:\n        balance_status = \"Moderately Imbalanced\"\n    else:\n        balance_status = \"Severely Imbalanced\"\n    \n    analysis_results['balance_status'] = balance_status\n    \n    print(\"--------------Analysis results------------------\")\n    print(analysis_results)\nelse:\n    print(\"No classes found in the dataset!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Visualisations**","metadata":{}},{"cell_type":"code","source":"#figure with multiple subplots\nfig = plt.figure(figsize=(25, 15))\n\n# Sort classes by count for better visualization(SHOW ONLY TOP 15)\nsorted_classes = dict(sorted(class_counts.items(), key=lambda x: x[1], reverse=True)[:15])\nclass_names = list(sorted_classes.keys())\nclass_values = list(sorted_classes.values())\n\n# Clean up class names(better readability)\nclean_class_names = [name.replace('_', ' ').title() for name in class_names]\n\n# Color scheme\ncolors = plt.cm.Set3(np.linspace(0, 1, len(class_names)))\n\n# Main bar plot - sorted by count (TOP 15 ONLY)\nax1 = plt.subplot(2, 3, 1)\nbars1 = ax1.bar(range(len(class_names)), class_values, color=colors)\nax1.set_title('Top 15 Classes by Count', fontsize=14, fontweight='bold')\nax1.set_xlabel('Classes', fontsize=12)\nax1.set_ylabel('Number of Images', fontsize=12)\nax1.set_xticks(range(len(class_names)))\nax1.set_xticklabels(clean_class_names, rotation=45, ha='right', fontsize=10)\n\n# value labels on bars\nfor i, bar in enumerate(bars1):\n    height = bar.get_height()\n    ax1.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n    f'{int(height)}', ha='center', va='bottom', fontweight='bold', fontsize=9)\n\n#average line\navg_line = analysis_results['average_per_class']\nax1.axhline(y=avg_line, color='red', linestyle='--', linewidth=2, \n            label=f'Average: {avg_line:.1f}')\nax1.legend()\n\n# Horizontal bar plot(TOP 10 ONLY)\nax2 = plt.subplot(2, 3, 2)\ntop_10_names = class_names[:10]\ntop_10_values = class_values[:10]\ntop_10_clean = clean_class_names[:10]\n\nbars2 = ax2.barh(range(len(top_10_names)), top_10_values, color=colors[:10])\nax2.set_title('Top 10 Classes (Horizontal)', fontsize=14, fontweight='bold')\nax2.set_xlabel('Number of Images', fontsize=12)\nax2.set_ylabel('Classes', fontsize=12)\nax2.set_yticks(range(len(top_10_names)))\nax2.set_yticklabels(top_10_clean, fontsize=11)\nax2.invert_yaxis()  # Highest count at top\n\n# Add value labels\nfor i, bar in enumerate(bars2):\n    width = bar.get_width()\n    ax2.text(width + width*0.01, bar.get_y() + bar.get_height()/2.,\n            f'{int(width)}', ha='left', va='center', fontweight='bold', fontsize=10)\n\n# Pie chart (TOP 8 ONLY )\nax3 = plt.subplot(2, 3, 3)\ntop_8_names = clean_class_names[:8]\ntop_8_values = class_values[:8]\nother_sum = sum(class_values[8:])\n\nif other_sum > 0:\n    pie_names = top_8_names + ['Others']\n    pie_values = top_8_values + [other_sum]\nelse:\n    pie_names = top_8_names\n    pie_values = top_8_values\n\nwedges, texts, autotexts = ax3.pie(pie_values, labels=pie_names, autopct='%1.1f%%',\n                                   colors=colors[:len(pie_values)], startangle=90)\nax3.set_title('Top 8 Classes Distribution', fontsize=14, fontweight='bold')\n\n# Make percentage text bold and adjust font size\nfor autotext in autotexts:\n    autotext.set_fontweight('bold')\n    autotext.set_fontsize(10)\n\n# Adjust label font size\nfor text in texts:\n    text.set_fontsize(9)\n\n# Statistics summary\nax4 = plt.subplot(2, 3, 4)\nax4.axis('off')\n\n# Create a clean statistics table\nstats_data = [\n    ['Total Classes', len(class_counts)],\n    ['Showing Top', len(class_names)],\n    ['Total Images', sum(class_counts.values())],\n    ['Average per Class', f'{analysis_results[\"average_per_class\"]:.1f}'],\n    ['Highest Count', max(class_counts.values())],\n    ['Lowest Count', min(class_counts.values())],\n    ['Standard Dev', f'{analysis_results.get(\"std_dev\", 0):.1f}']\n]\n\ntable = ax4.table(cellText=stats_data,\n                  colLabels=['Metric', 'Value'],\n                  cellLoc='center',\n                  loc='center',\n                  colWidths=[0.6, 0.4])\ntable.auto_set_font_size(False)\ntable.set_fontsize(11)\ntable.scale(1.2, 2)\n\nax4.set_title('Dataset Statistics', fontsize=14, fontweight='bold', pad=20)\n\n# Plant type grouping (if applicable)\nax5 = plt.subplot(2, 3, 5)\nplant_groups = {}\nfor class_name, count in class_counts.items():\n    if any(word in class_name.lower() for word in ['apple']):\n        plant_type = 'Apple'\n    elif any(word in class_name.lower() for word in ['tomato']):\n        plant_type = 'Tomato'\n    elif any(word in class_name.lower() for word in ['corn']):\n        plant_type = 'Corn'\n    elif any(word in class_name.lower() for word in ['potato']):\n        plant_type = 'Potato'\n    elif any(word in class_name.lower() for word in ['pepper']):\n        plant_type = 'Pepper'\n    else:\n        plant_type = 'Other'\n    \n    if plant_type not in plant_groups:\n        plant_groups[plant_type] = 0\n    plant_groups[plant_type] += count\n\nif len(plant_groups) > 1:\n    wedges2, texts2, autotexts2 = ax5.pie(plant_groups.values(), \n                                          labels=plant_groups.keys(), \n                                          autopct='%1.1f%%',\n                                          startangle=90,\n                                          colors=plt.cm.Set2(np.linspace(0, 1, len(plant_groups))))\n    ax5.set_title('Distribution by Plant Type', fontsize=14, fontweight='bold')\n    \n    for text in texts2:\n        text.set_fontsize(11)\n        text.set_fontweight('bold')\n    for autotext in autotexts2:\n        autotext.set_fontsize(10)\n        autotext.set_fontweight('bold')\nelse:\n    ax5.text(0.5, 0.5, 'Single Plant Type\\nDataset', ha='center', va='center', \n             fontsize=14, fontweight='bold', transform=ax5.transAxes)\n    ax5.set_title('Plant Type Analysis', fontsize=14, fontweight='bold')\n\n# Balance analysis\nax6 = plt.subplot(2, 3, 6)\nhealthy_count = sum(count for class_name, count in class_counts.items() \n                   if 'healthy' in class_name.lower())\ndisease_count = sum(count for class_name, count in class_counts.items() \n                   if 'healthy' not in class_name.lower())\n\nif healthy_count > 0 and disease_count > 0:\n    categories = ['Healthy', 'Disease']\n    counts = [healthy_count, disease_count]\n    colors_balance = ['lightgreen', 'lightcoral']\n    \n    bars6 = ax6.bar(categories, counts, color=colors_balance)\n    ax6.set_title('Healthy vs Disease Classes', fontsize=14, fontweight='bold')\n    ax6.set_ylabel('Total Images', fontsize=12)\n    \n    for i, bar in enumerate(bars6):\n        height = bar.get_height()\n        ax6.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n                f'{int(height)}', ha='center', va='bottom', fontweight='bold')\nelse:\n    ax6.text(0.5, 0.5, 'No Healthy/Disease\\nClassification Available', \n             ha='center', va='center', fontsize=12, fontweight='bold', \n             transform=ax6.transAxes)\n    ax6.set_title('Class Balance Analysis', fontsize=14, fontweight='bold')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"EPOCHS = 40  \nBATCH_SIZE = 32  \nIMG_SIZE = 224 \nVALIDATION_SPLIT = 0.2\nLEARNING_RATE = 0.001 \n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check validation directory\nvalid_dir = \"/kaggle/input/crop-disease-dataset/disease/valid\"\nall_valid_classes = os.listdir(valid_dir)\nprint(f\"All validation classes ({len(all_valid_classes)}):\")\nfor i, cls in enumerate(all_valid_classes):\n    print(f\"{i+1}. {cls}\")\n\n# Define classes to keep\nclasses_to_keep = [\n    'Tomato___Late_blight', 'Corn_(maize)___healthy', 'Pepper,_bell___Bacterial_spot',\n    'Tomato___Spider_mites Two-spotted_spider_mite', 'Tomato___Leaf_Mold', 'Corn_(maize)___Common_rust_',\n    'Potato___Early_blight', 'Apple___healthy', 'Tomato___Tomato_mosaic_virus', 'Potato___Late_blight',\n    'Pepper,_bell___healthy', 'Tomato___Target_Spot', 'Apple___Cedar_apple_rust', 'Apple___Black_rot',\n    'Tomato___Tomato_Yellow_Leaf_Curl_Virus', 'Tomato___Bacterial_spot', 'Apple___Apple_scab',\n    'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Tomato___Septoria_leaf_spot',\n    'Tomato___Early_blight', 'Corn_(maize)___Northern_Leaf_Blight', 'Potato___healthy', 'Tomato___healthy'\n]\n\nprint(len(classes_to_keep))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"crop_classes = len(classes_to_keep)\nprint(f\"Number of classes to train on: {crop_classes}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#augment the images\n\ntrain_datagen=ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=10,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n    brightness_range=[0.8, 1.2],\n    fill_mode='nearest',\n    validation_split=VALIDATION_SPLIT\n)\n\nvalidation_datagen=ImageDataGenerator(\n   rescale=1./255,\n   validation_split=VALIDATION_SPLIT\n)\n\n#training generator\ntrain_generator=train_datagen.flow_from_directory(\n    \"/kaggle/input/crop-disease-dataset/disease/train\",\n    target_size=(IMG_SIZE,IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='training',\n    shuffle=True\n)\n\nvalidation_generator=validation_datagen.flow_from_directory(\n    \"/kaggle/input/crop-disease-dataset/disease/valid\",\n    target_size=(IMG_SIZE,IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode='categorical',\n    subset='validation',\n    shuffle=False,\n    classes=classes_to_keep\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Model building with distributed strategy\nstrategy = tf.distribute.MirroredStrategy()\nprint(f\"Number of devices: {strategy.num_replicas_in_sync}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Get number of classes\ncrop_classes = len(train_generator.class_indices)\nprint(f\"Number of classes: {crop_classes}\")\nprint(f\"Class indices: {train_generator.class_indices}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = Sequential()\n# First layer\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Dropout(0.2))\n        \n# Second layer\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Dropout(0.2))\n        \n# Third layer\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Dropout(0.3))\n\n# fourth layer\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(2, 2))\nmodel.add(Dropout(0.3))\n        \n# Dense layers\nmodel.add(GlobalAveragePooling2D())# generalization\nmodel.add(Dense(128, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\nmodel.add(Dense(crop_classes, activation='softmax'))\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#compile the model\nmodel.compile(optimizer=Adam(learning_rate=0.0005),loss='categorical_crossentropy',metrics=['accuracy'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*50)\nprint(\"MODEL SUMMARY\")\nprint(\"=\"*50)\nmodel.summary()#summary","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#callbacks\nearlystopping=EarlyStopping(patience=5,restore_best_weights=True,monitor='val_accuracy',verbose=1)\nmodel_checkpoint=ModelCheckpoint('crop_disease_model.h5',monitor='val_accuracy',save_best_only=True,mode='max')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate steps\ntrain_steps = train_generator.samples // BATCH_SIZE\nvalidation_steps = validation_generator.samples // BATCH_SIZE\n\nprint('-------------------------------------------')\nprint(f\"Training samples: {train_generator.samples}\")\nprint(f\"Validation samples: {validation_generator.samples}\")\nprint(f\"Training steps per epoch: {train_steps}\")\nprint(f\"Validation steps per epoch: {validation_steps}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#train\nhistory = model.fit(\n    train_generator,\n    epochs=EPOCHS,\n    validation_data=validation_generator,\n    callbacks=[earlystopping, model_checkpoint],\n    verbose=1\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# After training\nmodel.save('/kaggle/working/crop_disease_model.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Evaluate the model\ntest_loss, test_accuracy = model.evaluate(validation_generator, steps=validation_steps)\nprint(f\"Test Accuracy: {test_accuracy:.4f}\")\nprint(f\"Test Loss: {test_loss:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# After training\nmodel.save('/kaggle/working/crop_disease_model.h5')\n\n# Also save additional files you might need\nimport json\nimport pickle\n\n# Save model info\nmodel_info = {\n    'accuracy': float(max(history.history['val_accuracy'])),\n    'input_shape': model.input_shape,\n    'output_shape': model.output_shape,\n    'classes': list(train_generator.class_indices.keys()),  # if using ImageDataGenerator\n    'training_date': '2024-07-14'\n}\n\nwith open('/kaggle/working/model_info.json', 'w') as f:\n    json.dump(model_info, f, indent=2)\n\n# Save training history\nwith open('/kaggle/working/training_history.pkl', 'wb') as f:\n    pickle.dump(history.history, f)\n\nprint(\"Files saved to /kaggle/working/\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_training_history(history):\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n    \n    # Plot training & validation accuracy\n    ax1.plot(history.history['accuracy'], label='Training Accuracy', linewidth=2)\n    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy', linewidth=2)\n    ax1.set_title('Model Accuracy', fontsize=14, fontweight='bold')\n    ax1.set_xlabel('Epoch')\n    ax1.set_ylabel('Accuracy')\n    ax1.legend()\n    ax1.grid(True, alpha=0.3)\n    \n    # Plot training & validation loss\n    ax2.plot(history.history['loss'], label='Training Loss', linewidth=2)\n    ax2.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n    ax2.set_title('Model Loss', fontsize=14, fontweight='bold')\n    ax2.set_xlabel('Epoch')\n    ax2.set_ylabel('Loss')\n    ax2.legend()\n    ax2.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    plt.show()\n\n# Plot training history\nplot_training_history(history)\n\n# Load best model for evaluation\nmodel.load_weights('best_crop_disease_model.h5')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate the model\nprint(\"\\n\" + \"=\"*50)\nprint(\"FINAL EVALUATION\")\nprint(\"=\"*50)\n\ntest_loss, test_accuracy = model.evaluate(validation_generator, steps=validation_steps)\nprint(f\"Final Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\nprint(f\"Final Test Loss: {test_loss:.4f}\")\n\n# Check if target accuracy is reached\nif test_accuracy >= 0.96:\n    print(\"🎉 TARGET ACCURACY ACHIEVED! Model performs at 96%+ accuracy!\")\nelse:\n    print(f\"Target accuracy not yet reached. Current: {test_accuracy*100:.2f}%\")\n    print(\"Consider: More epochs, different augmentation, or model architecture adjustments\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def predict_image(image_path, model, class_indices):\n    try:\n        # Load and preprocess image\n        img = keras.preprocessing.image.load_img(image_path, target_size=(IMG_SIZE, IMG_SIZE))\n        img_array = keras.preprocessing.image.img_to_array(img)\n        img_array = np.expand_dims(img_array, axis=0) / 255.0\n        \n        # Make prediction\n        predictions = model.predict(img_array, verbose=0)\n        predicted_class_index = np.argmax(predictions[0])\n        confidence = predictions[0][predicted_class_index]\n        \n        # Get class name\n        class_names = {v: k for k, v in class_indices.items()}\n        predicted_class = class_names[predicted_class_index]\n        \n        return predicted_class, confidence\n    except Exception as e:\n        print(f\"Error predicting image: {e}\")\n        return None, 0.0\n\nprint(f'\\nTo use prediction: predict_image(\"/kaggle/input/crop-disease-dataset/disease/test/AppleCedarRust1.JPG\", model, train_generator.class_indices)')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Add this for better evaluation\nfrom sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n\ndef evaluate_model_thoroughly(model, validation_generator):\n    # Get predictions\n    predictions = model.predict(validation_generator, verbose=1)\n    predicted_classes = np.argmax(predictions, axis=1)\n    \n    # Get true labels\n    true_classes = validation_generator.classes\n    \n    # Generate reports\n    class_names = list(validation_generator.class_indices.keys())\n    \n    print(\"Classification Report:\")\n    print(classification_report(true_classes, predicted_classes, target_names=class_names))\n    \n    print(\"\\nConfusion Matrix:\")\n    print(confusion_matrix(true_classes, predicted_classes))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Install required library\n!pip install pydrive\n\nfrom pydrive.auth import GoogleAuth\nfrom pydrive.drive import GoogleDrive\nfrom google.colab import auth\nfrom oauth2client.client import GoogleCredentials\n\n# Authenticate and upload\nauth.authenticate_user()\ngauth = GoogleAuth()\ngauth.credentials = GoogleCredentials.get_application_default()\ndrive = GoogleDrive(gauth)\n\n# Upload model\nuploaded = drive.CreateFile({'title': 'crop_disease_model.h5'})\nuploaded.SetContentFile('/kaggle/working/crop_disease_model.h5')\nuploaded.Upload()\n\nprint(f\"Model uploaded to Google Drive with ID: {uploaded['id']}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}