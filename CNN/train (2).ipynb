{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df693180",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications import EfficientNetB0  # Added for transfer learning\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "import hashlib\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a6bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset analysis\n",
    "DATASET_DIR = \"disease/train\"\n",
    "class_counts = {}\n",
    "for class_name in os.listdir(DATASET_DIR):\n",
    "    class_path = os.path.join(DATASET_DIR, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        images = [f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        class_counts[class_name] = len(images)\n",
    "\n",
    "print(\"----------------------Class Distribution:--------------------------\\n\")\n",
    "for class_name, count in class_counts.items():\n",
    "    print(f\"{class_name}: {count} images\")\n",
    "\n",
    "# Total images and classes calculation\n",
    "total_images = sum(class_counts.values())\n",
    "n_classes = len(class_counts)\n",
    "print(f\"\\n----------------------------------Dataset Summary:-----------------------\")\n",
    "print(f\"Total images: {total_images}\")\n",
    "print(f\"Number of classes: {n_classes}\")\n",
    "print(f\"Average images per class: {total_images/n_classes:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14484f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find min and max class sizes\n",
    "min_images = min(class_counts.values())\n",
    "max_images = max(class_counts.values())\n",
    "min_class_name = min(class_counts, key=class_counts.get)\n",
    "max_class_name = max(class_counts, key=class_counts.get)\n",
    "print(f\"Smallest class \\n{min_class_name}=> {min_images} images\\n\")\n",
    "print(f\"Largest class \\n{max_class_name}=> {max_images} images\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dca633",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-------------------Counting images in each class----------------------------------\")\n",
    "image_extensions=('.jpg', '.jpeg', '.png')      \n",
    "for class_name in os.listdir(DATASET_DIR):\n",
    "    class_path = os.path.join(DATASET_DIR, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        images = [f for f in os.listdir(class_path) \n",
    "        if f.lower().endswith(image_extensions)]\n",
    "        class_counts[class_name] = len(images)\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d207ada9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset balance analysis\n",
    "if class_counts: \n",
    "    counts = list(class_counts.values())\n",
    "    total_images = sum(counts)\n",
    "    n_classes = len(class_counts)\n",
    "    \n",
    "    analysis_results = {\n",
    "        'total_images': total_images,\n",
    "        'n_classes': n_classes,\n",
    "        'average_per_class': total_images / n_classes,\n",
    "        'min_images': min(counts),\n",
    "        'max_images': max(counts),\n",
    "        'std_dev': np.std(counts),\n",
    "        'median': np.median(counts)\n",
    "    }\n",
    "    \n",
    "    min_class = min(class_counts, key=class_counts.get)\n",
    "    max_class = max(class_counts, key=class_counts.get)\n",
    "    \n",
    "    analysis_results['min_class'] = min_class\n",
    "    analysis_results['max_class'] = max_class\n",
    "    \n",
    "    imbalance_ratio = analysis_results['max_images'] / analysis_results['min_images']\n",
    "    analysis_results['imbalance_ratio'] = imbalance_ratio\n",
    "    \n",
    "    if imbalance_ratio < 2:\n",
    "        balance_status = \"Well Balanced\"\n",
    "    elif imbalance_ratio < 5:\n",
    "        balance_status = \"Slightly Imbalanced\"\n",
    "    elif imbalance_ratio < 10:\n",
    "        balance_status = \"Moderately Imbalanced\"\n",
    "    else:\n",
    "        balance_status = \"Severely Imbalanced\"\n",
    "    \n",
    "    analysis_results['balance_status'] = balance_status\n",
    "    \n",
    "    print(\"--------------Analysis results------------------\")\n",
    "    print(analysis_results)\n",
    "else:\n",
    "    print(\"No classes found in the dataset!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443b7104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#figure with multiple subplots\n",
    "fig = plt.figure(figsize=(25, 15))\n",
    "\n",
    "# Sort classes by count for better visualization(SHOW ONLY TOP 15)\n",
    "sorted_classes = dict(sorted(class_counts.items(), key=lambda x: x[1], reverse=True)[:15])\n",
    "class_names = list(sorted_classes.keys())\n",
    "class_values = list(sorted_classes.values())\n",
    "\n",
    "# Clean up class names(better readability)\n",
    "clean_class_names = [name.replace('_', ' ').title() for name in class_names]\n",
    "\n",
    "# Color scheme\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(class_names)))\n",
    "\n",
    "# Main bar plot - sorted by count (TOP 15 ONLY)\n",
    "ax1 = plt.subplot(2, 3, 1)\n",
    "bars1 = ax1.bar(range(len(class_names)), class_values, color=colors)\n",
    "ax1.set_title('Top 15 Classes by Count', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Classes', fontsize=12)\n",
    "ax1.set_ylabel('Number of Images', fontsize=12)\n",
    "ax1.set_xticks(range(len(class_names)))\n",
    "ax1.set_xticklabels(clean_class_names, rotation=45, ha='right', fontsize=10)\n",
    "\n",
    "# value labels on bars\n",
    "for i, bar in enumerate(bars1):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "    f'{int(height)}', ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "\n",
    "#average line\n",
    "avg_line = analysis_results['average_per_class']\n",
    "ax1.axhline(y=avg_line, color='red', linestyle='--', linewidth=2, \n",
    "            label=f'Average: {avg_line:.1f}')\n",
    "ax1.legend()\n",
    "\n",
    "# Horizontal bar plot(TOP 10 ONLY)\n",
    "ax2 = plt.subplot(2, 3, 2)\n",
    "top_10_names = class_names[:10]\n",
    "top_10_values = class_values[:10]\n",
    "top_10_clean = clean_class_names[:10]\n",
    "\n",
    "bars2 = ax2.barh(range(len(top_10_names)), top_10_values, color=colors[:10])\n",
    "ax2.set_title('Top 10 Classes (Horizontal)', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Number of Images', fontsize=12)\n",
    "ax2.set_ylabel('Classes', fontsize=12)\n",
    "ax2.set_yticks(range(len(top_10_names)))\n",
    "ax2.set_yticklabels(top_10_clean, fontsize=11)\n",
    "ax2.invert_yaxis()  # Highest count at top\n",
    "\n",
    "# Add value labels\n",
    "for i, bar in enumerate(bars2):\n",
    "    width = bar.get_width()\n",
    "    ax2.text(width + width*0.01, bar.get_y() + bar.get_height()/2.,\n",
    "            f'{int(width)}', ha='left', va='center', fontweight='bold', fontsize=10)\n",
    "\n",
    "# Pie chart (TOP 8 ONLY )\n",
    "ax3 = plt.subplot(2, 3, 3)\n",
    "top_8_names = clean_class_names[:8]\n",
    "top_8_values = class_values[:8]\n",
    "other_sum = sum(class_values[8:])\n",
    "\n",
    "if other_sum > 0:\n",
    "    pie_names = top_8_names + ['Others']\n",
    "    pie_values = top_8_values + [other_sum]\n",
    "else:\n",
    "    pie_names = top_8_names\n",
    "    pie_values = top_8_values\n",
    "\n",
    "wedges, texts, autotexts = ax3.pie(pie_values, labels=pie_names, autopct='%1.1f%%',\n",
    "                                   colors=colors[:len(pie_values)], startangle=90)\n",
    "ax3.set_title('Top 8 Classes Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Make percentage text bold and adjust font size\n",
    "for autotext in autotexts:\n",
    "    autotext.set_fontweight('bold')\n",
    "    autotext.set_fontsize(10)\n",
    "\n",
    "# Adjust label font size\n",
    "for text in texts:\n",
    "    text.set_fontsize(9)\n",
    "\n",
    "# Statistics summary\n",
    "ax4 = plt.subplot(2, 3, 4)\n",
    "ax4.axis('off')\n",
    "\n",
    "# Create a clean statistics table\n",
    "stats_data = [\n",
    "    ['Total Classes', len(class_counts)],\n",
    "    ['Showing Top', len(class_names)],\n",
    "    ['Total Images', sum(class_counts.values())],\n",
    "    ['Average per Class', f'{analysis_results[\"average_per_class\"]:.1f}'],\n",
    "    ['Highest Count', max(class_counts.values())],\n",
    "    ['Lowest Count', min(class_counts.values())],\n",
    "    ['Standard Dev', f'{analysis_results.get(\"std_dev\", 0):.1f}']\n",
    "]\n",
    "\n",
    "table = ax4.table(cellText=stats_data,\n",
    "                  colLabels=['Metric', 'Value'],\n",
    "                  cellLoc='center',\n",
    "                  loc='center',\n",
    "                  colWidths=[0.6, 0.4])\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(1.2, 2)\n",
    "\n",
    "ax4.set_title('Dataset Statistics', fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "# Plant type grouping (if applicable)\n",
    "ax5 = plt.subplot(2, 3, 5)\n",
    "plant_groups = {}\n",
    "for class_name, count in class_counts.items():\n",
    "    if any(word in class_name.lower() for word in ['apple']):\n",
    "        plant_type = 'Apple'\n",
    "    elif any(word in class_name.lower() for word in ['tomato']):\n",
    "        plant_type = 'Tomato'\n",
    "    elif any(word in class_name.lower() for word in ['corn']):\n",
    "        plant_type = 'Corn'\n",
    "    elif any(word in class_name.lower() for word in ['potato']):\n",
    "        plant_type = 'Potato'\n",
    "    elif any(word in class_name.lower() for word in ['pepper']):\n",
    "        plant_type = 'Pepper'\n",
    "    else:\n",
    "        plant_type = 'Other'\n",
    "    \n",
    "    if plant_type not in plant_groups:\n",
    "        plant_groups[plant_type] = 0\n",
    "    plant_groups[plant_type] += count\n",
    "\n",
    "if len(plant_groups) > 1:\n",
    "    wedges2, texts2, autotexts2 = ax5.pie(plant_groups.values(), \n",
    "                                          labels=plant_groups.keys(), \n",
    "                                          autopct='%1.1f%%',\n",
    "                                          startangle=90,\n",
    "                                          colors=plt.cm.Set2(np.linspace(0, 1, len(plant_groups))))\n",
    "    ax5.set_title('Distribution by Plant Type', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    for text in texts2:\n",
    "        text.set_fontsize(11)\n",
    "        text.set_fontweight('bold')\n",
    "    for autotext in autotexts2:\n",
    "        autotext.set_fontsize(10)\n",
    "        autotext.set_fontweight('bold')\n",
    "else:\n",
    "    ax5.text(0.5, 0.5, 'Single Plant Type\\nDataset', ha='center', va='center', \n",
    "             fontsize=14, fontweight='bold', transform=ax5.transAxes)\n",
    "    ax5.set_title('Plant Type Analysis', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Balance analysis\n",
    "ax6 = plt.subplot(2, 3, 6)\n",
    "healthy_count = sum(count for class_name, count in class_counts.items() \n",
    "                   if 'healthy' in class_name.lower())\n",
    "disease_count = sum(count for class_name, count in class_counts.items() \n",
    "                   if 'healthy' not in class_name.lower())\n",
    "\n",
    "if healthy_count > 0 and disease_count > 0:\n",
    "    categories = ['Healthy', 'Disease']\n",
    "    counts = [healthy_count, disease_count]\n",
    "    colors_balance = ['lightgreen', 'lightcoral']\n",
    "    \n",
    "    bars6 = ax6.bar(categories, counts, color=colors_balance)\n",
    "    ax6.set_title('Healthy vs Disease Classes', fontsize=14, fontweight='bold')\n",
    "    ax6.set_ylabel('Total Images', fontsize=12)\n",
    "    \n",
    "    for i, bar in enumerate(bars6):\n",
    "        height = bar.get_height()\n",
    "        ax6.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "                f'{int(height)}', ha='center', va='bottom', fontweight='bold')\n",
    "else:\n",
    "    ax6.text(0.5, 0.5, 'No Healthy/Disease\\nClassification Available', \n",
    "             ha='center', va='center', fontsize=12, fontweight='bold', \n",
    "             transform=ax6.transAxes)\n",
    "    ax6.set_title('Class Balance Analysis', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fb3cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10 \n",
    "BATCH_SIZE = 128 \n",
    "IMG_SIZE = 224 \n",
    "VALIDATION_SPLIT = 0.2\n",
    "LEARNING_RATE = 0.001 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03afece",
   "metadata": {},
   "outputs": [],
   "source": [
    "#augment the images\n",
    "\n",
    "train_datagen=ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest',\n",
    "    validation_split=VALIDATION_SPLIT\n",
    ")\n",
    "\n",
    "validation_datagen=ImageDataGenerator(\n",
    "   rescale=1./255,\n",
    "   validation_split=VALIDATION_SPLIT\n",
    ")\n",
    "\n",
    "#training generator\n",
    "train_generator=train_datagen.flow_from_directory(\n",
    "    os.path.join('disease','train'),\n",
    "    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "validation_generator=validation_datagen.flow_from_directory(\n",
    "    os.path.join('disease','valid'),\n",
    "    target_size=(IMG_SIZE,IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494a8581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of classes\n",
    "crop_classes = len(train_generator.class_indices)\n",
    "print(f\"Number of classes: {crop_classes}\")\n",
    "print(f\"Class indices: {train_generator.class_indices}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd67918",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# First layer\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Dropout(0.2))\n",
    "        \n",
    "# Second layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Dropout(0.2))\n",
    "        \n",
    "# Third layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# fourth layer\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Dropout(0.3))\n",
    "        \n",
    "# Dense layers\n",
    "model.add(GlobalAveragePooling2D())# generalization\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(crop_classes, activation='softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8be5b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa934e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285c2d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks\n",
    "earlystopping=EarlyStopping(patience=5,restore_best_weights=True,monitor='val_accuracy',verbose=1)\n",
    "model_checkpoint=ModelCheckpoint('crop_disease_model.h5',monitor='val_accuracy',save_best_only=True,mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115ae2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#steps per epoch\n",
    "train_steps = train_generator.samples // BATCH_SIZE\n",
    "validation_steps = validation_generator.samples // BATCH_SIZE\n",
    "\n",
    "print('-------------------------------------------')\n",
    "print(f\"Training samples: {train_generator.samples}\")\n",
    "print(f\"Validation samples: {validation_generator.samples}\")\n",
    "print(f\"Training steps per epoch: {train_steps}\")\n",
    "print(f\"Validation steps per epoch: {validation_steps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd715f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[earlystopping, model_checkpoint],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde56950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot training & validation accuracy\n",
    "    ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot training & validation loss\n",
    "    ax2.plot(history.history['loss'], label='Training Loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the training history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8274df8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(validation_generator, steps=validation_steps)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
